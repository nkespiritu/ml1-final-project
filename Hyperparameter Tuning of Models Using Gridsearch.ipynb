{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of Models Using Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# setup\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, r2_score, \\\n",
    "                            mean_absolute_error, mean_squared_error\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# regressors\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./taxi_tnp_weather.csv.gz', low_memory=False,\n",
    "                 parse_dates=['trip_end_timestamp', 'trip_start_timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_hour'] = df.trip_start_timestamp.dt.hour\n",
    "df['start_day'] = df.trip_start_timestamp.dt.weekday\n",
    "df['start_month'] = df.trip_start_timestamp.dt.month\n",
    "\n",
    "df['end_hour'] = df.trip_end_timestamp.dt.hour\n",
    "df['end_day'] = df.trip_end_timestamp.dt.weekday\n",
    "df['end_month'] = df.trip_end_timestamp.dt.month\n",
    "\n",
    "df.loc[:, 'fare_per_sec'] = df.fare / df.trip_seconds\n",
    "df.loc[:, 'fare_per_mile'] = df.fare / df.trip_miles\n",
    "df.loc[:, 'tip_per_sec'] = df.tip / df.trip_seconds\n",
    "df.loc[:, 'tip_per_mile'] = df.tip / df.trip_miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_cols = ['dropoff_community_area', 'fare', 'payment_type',\n",
    "                'pickup_community_area', 'trip_miles', 'trip_seconds',\n",
    "                'additional_charges', 'start_hour', 'start_day', \n",
    "                'start_month', 'end_hour', 'end_day', 'end_month', \n",
    "                'fare_per_sec', 'fare_per_mile']\n",
    "\n",
    "to_convert_cols = ['dropoff_community_area', 'pickup_community_area', \n",
    "                   'start_hour', 'start_day', 'start_month', 'end_hour', \n",
    "                   'end_day', 'end_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup for Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_tip_df = df.copy()\n",
    "has_tip_df['has_tip'] = has_tip_df['tip'].map(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_features = has_tip_df[has_tip_df.TransportType=='taxi'][allowed_cols]\n",
    "clf_target = has_tip_df[has_tip_df.TransportType=='taxi']['has_tip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dropoff_community_area     object\n",
       "fare                      float64\n",
       "payment_type               object\n",
       "pickup_community_area      object\n",
       "trip_miles                float64\n",
       "trip_seconds              float64\n",
       "additional_charges        float64\n",
       "start_hour                 object\n",
       "start_day                  object\n",
       "start_month                object\n",
       "end_hour                   object\n",
       "end_day                    object\n",
       "end_month                  object\n",
       "fare_per_sec              float64\n",
       "fare_per_mile             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_features[to_convert_cols] = clf_features[to_convert_cols].astype(str)\n",
    "clf_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240304, 251), (240304,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_features = pd.get_dummies(clf_features)\n",
    "clf_features.shape, clf_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 classifier models to be trained using gridsearch with 10-fold cross validation. The models are:\n",
    "- GaussianNB\n",
    "- LogisticRegression\n",
    "- LGBMClassifier\n",
    "- LinearSVC\n",
    "- KNeighborsClassifier\n",
    "- RandomForestClassifier\n",
    "- DecisionTreeClassifier\n",
    "- ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clf, X_test_clf,\\\n",
    "y_train_clf, y_test_clf = train_test_split(clf_features, clf_target, \n",
    "                                           test_size=0.3, random_state=0, \n",
    "                                           stratify=clf_target)\n",
    "\n",
    "clf_results = []\n",
    "models = [\n",
    "    {'model': GaussianNB(),\n",
    "     'params': {}\n",
    "    },\n",
    "\n",
    "    {'model': LogisticRegression(tol=1e-6),\n",
    "     'params': {\n",
    "         'C': [10, 100],\n",
    "         'C': [1e-4, 1e-2, 1, 10, 100],\n",
    "         'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "         'solver': ['saga', 'liblinear']\n",
    "     }\n",
    "    },\n",
    "    {'model': LGBMClassifier(),\n",
    "     'params': {    \n",
    "        'learning_rate': [0.07, 0.1, 0.12],\n",
    "        'n_estimators': [100, 300],\n",
    "        'max_depth': [5, 10, 15]\n",
    "     }\n",
    "    },\n",
    "    {'model': LinearSVC(tol=1e-6),\n",
    "     'params': {\n",
    "         'C': [1e-4, 1e-2, 1, 10, 100],\n",
    "         'penalty': ['l1', 'l2']\n",
    "     }\n",
    "    },\n",
    "    {'model': KNeighborsClassifier(n_jobs=-1),\n",
    "     'params': {\n",
    "         'n_neighbors': [5, 10, 15],\n",
    "     }\n",
    "    },\n",
    "    {'model': RandomForestClassifier(),\n",
    "     'params': {\n",
    "         'n_estimators': [300, 500],\n",
    "         'max_depth': [5, 10, 15],\n",
    "     }\n",
    "    },\n",
    "    {'model': DecisionTreeClassifier(),\n",
    "     'params': {\n",
    "         'max_depth': [5, 10],\n",
    "     }\n",
    "    },\n",
    "    {'model': ExtraTreesClassifier(n_jobs=-1),\n",
    "     'params': {\n",
    "         'n_estimators': [300, 500],\n",
    "         'max_depth': [5, 10],  \n",
    "     }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"starting Gridsearch\")\n",
    "for i in tqdm(models):\n",
    "\n",
    "    modelname = type(i['model']).__name__\n",
    "    gs = GridSearchCV(i['model'], i['params'], verbose=2, n_jobs=-1, cv=10)\n",
    "    gs = gs.fit(X_train_clf, y_train_clf)\n",
    "    print(modelname, ': ', gs.best_score_)\n",
    "    \n",
    "    train_predicted = gs.predict(X_train_clf)\n",
    "    print(f'train score: {gs.score(X_train_clf, y_train_clf):.4f}')\n",
    "    print('train accuracy_score: '\n",
    "          f'{accuracy_score(y_train_clf, train_predicted):.4f}')\n",
    "    print(f'train f1_score: {f1_score(y_train_clf, train_predicted):.4f}')\n",
    "\n",
    "    test_predicted = gs.predict(X_test_clf)\n",
    "    print(f'test unseen data score: {gs.score(X_test_clf, y_test_clf):.4f}')\n",
    "    print('test unseen data accuracy_score: ', \n",
    "          f'{accuracy_score(y_test_clf, test_predicted):.4f}')\n",
    "    print('test unseen data f1_score: ', \n",
    "          f'{f1_score(y_test_clf, test_predicted):.4f}')\n",
    "\n",
    "    tmpgs = pd.DataFrame({\n",
    "        'model': modelname,\n",
    "        **gs.cv_results_\n",
    "    })\n",
    "#     print(f'saving to gridsearch-results-{modelname}.csv.gz')\n",
    "#     tmpgs.to_csv('gridsearch-results-' + modelname + '.csv.gz', index=False, compression='gzip')\n",
    "    clf_results.append(tmpgs)\n",
    "    print('==============================\\n')\n",
    "print(\"finished Gridsearch\")\n",
    "\n",
    "clf_results = pd.concat(clf_results).set_index('model').reset_index()\n",
    "clf_results = clf_results.drop(clf_results.columns[(clf_results.columns.str\\\n",
    "                    .contains(r'param_|split|std|rank_test_score'))], axis=1)\n",
    "\n",
    "clf_results.sort_values(by=['mean_test_score', 'mean_score_time', \n",
    "                            'mean_fit_time'], \n",
    "                        ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-run Results of Top 3 Ranked Accuracies for each Regressor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a processed output of a previously executed gridsearch since the cell above is expected to complete after a day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Model|Avg. Train Time (seconds)|Avg. Prediction Time (seconds)|Avg. Prediction Accuracy|Parameters|\n",
    "|-|:-:|:-:|:-:|-|\n",
    "|GaussianNB|11.28|1.04|96.10|{}|\n",
    "|LGBMClassifier|20.36|1.15|97.62|{'learning_rate': 0.07, 'max_depth': 10, 'n_estimators': 300}|\n",
    "|LGBMClassifier|18.18|1.01|97.62|{'learning_rate': 0.07, 'max_depth': 15, 'n_estimators': 300}|\n",
    "|LGBMClassifier|9.14|0.52|97.62|{'learning_rate': 0.12, 'max_depth': 5, 'n_estimators': 100}|\n",
    "|LogisticRegression|15.03|0.12|97.62|{'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}|\n",
    "|LogisticRegression|47.87|0.06|97.62|{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}|\n",
    "|LogisticRegression|390.76|0.09|97.61|{'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}|\n",
    "|LinearSVC|238.75|0.07|97.61|{'C': 0.0001, 'penalty': 'l2'}|\n",
    "|LinearSVC|215.47|0.09|97.51|{'C': 0.01, 'penalty': 'l2'}|\n",
    "|LinearSVC|239.71|0.09|97.39|{'C': 10, 'penalty': 'l2'}|\n",
    "|RandomForestClassifier|183.72|2.44|97.62|{'max_depth': 10, 'n_estimators': 300}|\n",
    "|RandomForestClassifier|302.48|3.96|97.62|{'max_depth': 10, 'n_estimators': 500}|\n",
    "|RandomForestClassifier|232.04|2.70|97.62|{'max_depth': 15, 'n_estimators': 300}|\n",
    "|DecisionTreeClassifier|6.64|0.09|97.60|{'max_depth': 5}|\n",
    "|DecisionTreeClassifier|12.19|0.09|97.55|{'max_depth': 10}|\n",
    "|ExtraTreesClassifier|66.40|1.14|97.62|{'max_depth': 5, 'n_estimators': 300}|\n",
    "|ExtraTreesClassifier|110.45|1.80|97.62|{'max_depth': 5, 'n_estimators': 500}|\n",
    "|ExtraTreesClassifier|136.74|1.89|97.62|{'max_depth': 10, 'n_estimators': 300}|\n",
    "|KNeighborsClassifier|31.90|43.53|86.36|{'n_neighbors': 15}|\n",
    "|KNeighborsClassifier|31.05|44.67|85.17|{'n_neighbors': 10}|\n",
    "|KNeighborsClassifier|30.88|42.54|83.92|{'n_neighbors': 5}|\n",
    "|XGBClassifier|1,188.64|0.87|97.61|{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 300}|\n",
    "|XGBClassifier|538.61|0.55|97.61|{'learning_rate': 0.07, 'max_depth': 5, 'n_estimators': 300}|\n",
    "|XGBClassifier|705.49|0.61|97.61|{'learning_rate': 0.07, 'max_depth': 5, 'n_estimators': 500}|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup for Regressor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropoff_community_area     object\n",
      "fare                      float64\n",
      "payment_type               object\n",
      "pickup_community_area      object\n",
      "trip_miles                float64\n",
      "trip_seconds              float64\n",
      "additional_charges        float64\n",
      "start_hour                 object\n",
      "start_day                  object\n",
      "start_month                object\n",
      "end_hour                   object\n",
      "end_day                    object\n",
      "end_month                  object\n",
      "fare_per_sec              float64\n",
      "fare_per_mile             float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(117735, 244)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_features = df[df['tip']>0][df.TransportType=='taxi'][allowed_cols]\n",
    "reg_target = df[df['tip']>0][df.TransportType=='taxi']['tip']\n",
    "reg_features[to_convert_cols] = reg_features[to_convert_cols].astype(str)\n",
    "print(reg_features.dtypes)\n",
    "reg_features = pd.get_dummies(reg_features)\n",
    "reg_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 regressor models to be trained using gridsearch with 10-fold cross validation. The models are:\n",
    "- LGBMRegressor\n",
    "- LinearRegression\n",
    "- Lasso\n",
    "- Ridge\n",
    "- RandomForestRegressor\n",
    "- DecisionTreeRegressor\n",
    "- KNeighborsRegressor\n",
    "- ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg, X_test_reg,\\\n",
    "y_train_reg, y_test_reg = train_test_split(reg_features, reg_target, \n",
    "                                           test_size=0.3, random_state=0)\n",
    "\n",
    "reg_results = []\n",
    "models = [\n",
    "    {'model': LinearRegression(),\n",
    "     'params': {}\n",
    "    },\n",
    "    {'model': Lasso(),\n",
    "     'params': {\n",
    "         'alpha': [1e-2, 0.1, 1],\n",
    "         'max_iter': [300, 500]\n",
    "     }\n",
    "    },\n",
    "    {'model': Ridge(),\n",
    "     'params': {\n",
    "         'alpha': [1e-2, 0.1, 1],\n",
    "         'max_iter': [300, 500],\n",
    "         'solver': ['saga', 'cholesky']\n",
    "     }\n",
    "    },\n",
    "    {'model': LGBMRegressor(),\n",
    "     'params': {    \n",
    "        'learning_rate': [0.07, 0.1, 0.12],\n",
    "        'n_estimators': [100, 300],\n",
    "        'max_depth': [5, 10, 15]\n",
    "     }\n",
    "    },\n",
    "    {'model': RandomForestRegressor(n_jobs=-1),\n",
    "     'params': {\n",
    "         'n_estimators': [300, 500],\n",
    "         'max_depth': [5, 10, 15],\n",
    "     }\n",
    "    },\n",
    "    {'model': DecisionTreeRegressor(),\n",
    "     'params': {\n",
    "         'max_depth': [5, 10],\n",
    "     }\n",
    "    },\n",
    "    {'model': KNeighborsRegressor(n_jobs=-1),\n",
    "     'params': {\n",
    "         'n_neighbors': [5, 10],\n",
    "     }\n",
    "    },\n",
    "    {'model': ExtraTreesRegressor(n_jobs=-1),\n",
    "     'params': {\n",
    "         'n_estimators': [300, 500],\n",
    "         'max_depth': [5, 10],  \n",
    "     }\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"starting Gridsearch\")\n",
    "for i in tqdm(models):\n",
    "\n",
    "    modelname = type(i['model']).__name__\n",
    "    gs = GridSearchCV(i['model'], i['params'], verbose=2, cv=10, n_jobs=-1, \n",
    "                      scoring=['neg_mean_squared_error', 'r2'], refit='r2')\n",
    "    gs = gs.fit(X_train_reg, y_train_reg)\n",
    "    print(modelname, ': ', gs.best_score_)\n",
    "\n",
    "    print(f'train score: {gs.score(X_train_reg, y_train_reg):.4f}')\n",
    "    print('train r2 score: '\n",
    "          f'{r2_score(y_train_reg, gs.predict(X_train_reg)):.4f}')\n",
    "    print('train root mean_squared_error: '\n",
    "  f'{np.sqrt(mean_squared_error(y_train_reg, gs.predict(X_train_reg))):.4f}')\n",
    "    print('train mean_absolute_error: '\n",
    "          f'{mean_absolute_error(y_train_reg, gs.predict(X_train_reg)):.4f}')\n",
    "\n",
    "    print(f'test unseen data score: {gs.score(X_test_reg, y_test_reg):.4f}')\n",
    "    print('test unseen data r2 score: '\n",
    "          f'{r2_score(y_test_reg, gs.predict(X_test_reg)):.4f}')\n",
    "    print('test unseen data root mean_squared_error: '\n",
    "  f'{np.sqrt(mean_squared_error(y_test_reg, gs.predict(X_test_reg))):.4f}')\n",
    "    print('test unseen data mean_absolute_error: '\n",
    "          f'{mean_absolute_error(y_test_reg, gs.predict(X_test_reg)):.4f}')\n",
    "    \n",
    "    tmpgs = pd.DataFrame({\n",
    "        'model': modelname,\n",
    "        **gs.cv_results_\n",
    "    })\n",
    "#     print(f'saving to gridsearch-results-{modelname}.csv.gz')\n",
    "#     tmpgs.to_csv(modelname + '.csv.gz', index=False, compression='gzip')\n",
    "    reg_results.append(tmpgs)\n",
    "    print('==============================\\n')\n",
    "\n",
    "print(\"finished Gridsearch\")\n",
    "\n",
    "reg_results = pd.concat(reg_results).set_index('model').reset_index()\n",
    "reg_results = reg_results.drop(reg_results.columns[(reg_results.columns\\\n",
    "                                                    .str.contains\\\n",
    "                        (r'param_|split|std|rank_test_'))], axis=1)\n",
    "\n",
    "reg_results.sort_values(by=['mean_test_r2', 'mean_score_time', \n",
    "                            'mean_fit_time'], \n",
    "                        ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-run Results of Top 3 Ranked Accuracies for each Regressor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a processed output of a previously executed gridsearch since the cell above is expected to complete after a day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Model|Avg. Train Time (seconds)|Avg. Prediction Time (seconds)|Avg. Prediction Accuracy|Avg. RMSE|Parameters|\n",
    "|-|:-:|:-:|:-:|:-:|-|\n",
    "|LinearRegression|1.86|0.02|77.02|1.51|{}|\n",
    "|LGBMRegressor|1.56|0.13|77.13|1.51|{'learning_rate': 0.07, 'max_depth': 5, 'n_estimators': 100}|\n",
    "|LGBMRegressor|12.89|1.22|77.09|1.51|{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}|\n",
    "|LGBMRegressor|16.89|1.10|77.08|1.51|{'learning_rate': 0.07, 'max_depth': 15, 'n_estimators': 100}|\n",
    "|Lasso|2.49|0.02|76.97|1.51|{'alpha': 0.01, 'max_iter': 300}|\n",
    "|Lasso|2.67|0.02|76.97|1.51|{'alpha': 0.01, 'max_iter': 500}|\n",
    "|Lasso|0.93|0.02|76.80|1.52|{'alpha': 0.1, 'max_iter': 300}|\n",
    "|Ridge|1.16|0.02|77.07|1.51|{'alpha': 1, 'max_iter': 300, 'solver': 'cholesky'}|\n",
    "|Ridge|0.99|0.03|77.07|1.51|{'alpha': 1, 'max_iter': 500, 'solver': 'cholesky'}|\n",
    "|Ridge|5.32|0.10|77.03|1.51|{'alpha': 0.1, 'max_iter': 300, 'solver': 'cholesky'}|\n",
    "|RandomForestRegressor|327.11|0.34|76.45|1.53|{'max_depth': 5, 'n_estimators': 300}|\n",
    "|RandomForestRegressor|518.83|0.52|76.40|1.53|{'max_depth': 5, 'n_estimators': 500}|\n",
    "|RandomForestRegressor|984.36|1.17|76.29|1.54|{'max_depth': 10, 'n_estimators': 500}|\n",
    "|DecisionTreeRegressor|1.94|0.03|72.20|1.62|{'max_depth': 5}|\n",
    "|DecisionTreeRegressor|3.40|0.03|71.92|1.70|{'max_depth': 10}|\n",
    "|ExtraTreesRegressor|619.96|0.55|76.78|1.52|{'max_depth': 10, 'n_estimators': 300}|\n",
    "|ExtraTreesRegressor|890.29|0.75|76.75|1.52|{'max_depth': 10, 'n_estimators': 500}|\n",
    "|ExtraTreesRegressor|276.04|0.33|75.54|1.56|{'max_depth': 5, 'n_estimators': 300}|\n",
    "|KNeighborsRegressor|11.07|10.35|74.14|1.60|{'n_neighbors': 10}|\n",
    "|KNeighborsRegressor|11.20|9.06|72.25|1.66|{'n_neighbors': 5}|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
